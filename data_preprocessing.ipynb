{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of compounds >> 68\n",
      "Number of descriptors >> 7\n"
     ]
    }
   ],
   "source": [
    "# Load the compounds data\n",
    "compounds = pd.read_csv(\"./data/compounds.csv\")\n",
    "num_compounds = compounds.shape[0]\n",
    "num_descriptors = compounds.shape[1] - 3\n",
    "print(f\"Number of compounds >> {num_compounds}\")\n",
    "print(f\"Number of descriptors >> {num_descriptors}\")  # Excluded 'ID', 'NAME', 'CLASS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>monomer_mw</th>\n",
       "      <th>XlogP3</th>\n",
       "      <th>h-bond_donors</th>\n",
       "      <th>h-bond_acceptors</th>\n",
       "      <th>complexity</th>\n",
       "      <th>concentration</th>\n",
       "      <th>polymer_mw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHAPS</td>\n",
       "      <td>Surfactant</td>\n",
       "      <td>614.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Triton X-100</td>\n",
       "      <td>Surfactant</td>\n",
       "      <td>527.7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alg</td>\n",
       "      <td>Polymer</td>\n",
       "      <td>448.5</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AP</td>\n",
       "      <td>Polymer</td>\n",
       "      <td>828.7</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>12690.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>213700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BSA</td>\n",
       "      <td>Protein</td>\n",
       "      <td>331.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>66000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          NAME       CLASS  monomer_mw  XlogP3  h-bond_donors  \\\n",
       "0   1         CHAPS  Surfactant       614.9     2.9            4.0   \n",
       "1   2  Triton X-100  Surfactant       527.7    -2.0         1190.0   \n",
       "2   3           Alg     Polymer       448.5    -3.6         2676.0   \n",
       "3   4            AP     Polymer       828.7   -10.6         6516.0   \n",
       "4   5           BSA     Protein       331.8    -2.3         1190.0   \n",
       "\n",
       "   h-bond_acceptors  complexity  concentration  polymer_mw  \n",
       "0               7.0      1030.0           20.0       614.0  \n",
       "1            1704.0       731.0           25.0     80000.0  \n",
       "2            4348.0       511.0            4.0    150000.0  \n",
       "3           12690.0      1210.0           10.0    213700.0  \n",
       "4            1704.0       391.0           40.0     66000.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pairs >> (68, 68)\n"
     ]
    }
   ],
   "source": [
    "# Load the solution mixture pairs\n",
    "pairs = np.genfromtxt(\"./data/pairs.csv\", delimiter=\",\")\n",
    "print(f\"Shape of pairs >> {pairs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 'compounds' data\n",
    "\n",
    "# Extract the descriptors\n",
    "descriptors = compounds.loc[:, \"monomer_mw\":]\n",
    "scaler = StandardScaler()\n",
    "norm_descriptors = scaler.fit_transform(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lower triangular part of the pairs matrix\n",
    "pairs_tril_indices = np.tril_indices_from(pairs, k=-1)\n",
    "pairs_tril = pairs[pairs_tril_indices]\n",
    "\n",
    "# Split data into train & validate\n",
    "np.random.seed(42)\n",
    "\n",
    "num_pairs = pairs_tril.size\n",
    "\n",
    "# Training set\n",
    "num_training_examples = int(0.7 * num_pairs)\n",
    "\n",
    "training_indices_flat = np.random.choice(\n",
    "    num_pairs, num_training_examples, replace=False\n",
    ")\n",
    "\n",
    "training_indices_rows = pairs_tril_indices[0][training_indices_flat]\n",
    "training_indices_cols = pairs_tril_indices[1][training_indices_flat]\n",
    "\n",
    "training_indices = tuple(zip(training_indices_rows, training_indices_cols))\n",
    "\n",
    "# Validation set\n",
    "val_indices_flat = np.setdiff1d(np.arange(num_pairs), training_indices_flat)\n",
    "val_indices_rows = pairs_tril_indices[0][val_indices_flat]\n",
    "val_indices_cols = pairs_tril_indices[1][val_indices_flat]\n",
    "\n",
    "val_indices = tuple(zip(val_indices_rows, val_indices_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make actual training data & map labels\n",
    "X_train_shape = (len(training_indices), 2 * num_descriptors)\n",
    "X_train = np.zeros(X_train_shape)\n",
    "Y_train = np.zeros(len(training_indices))\n",
    "\n",
    "for i, pair in enumerate(training_indices):\n",
    "    compound1 = pair[0]\n",
    "    compound2 = pair[1]\n",
    "    X_train[i, :num_descriptors] = norm_descriptors[compound1, :]\n",
    "    X_train[i, num_descriptors:] = norm_descriptors[compound2, :]\n",
    "    Y_train[i] = pairs[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation data\n",
    "X_val_shape = (len(val_indices), 2 * num_descriptors)\n",
    "X_val = np.zeros(X_val_shape)\n",
    "Y_val = np.zeros(len(val_indices))\n",
    "\n",
    "for i, pair in enumerate(val_indices):\n",
    "    compound1 = pair[0]\n",
    "    compound2 = pair[1]\n",
    "    X_val[i, :num_descriptors] = norm_descriptors[compound1, :]\n",
    "    X_val[i, num_descriptors:] = norm_descriptors[compound2, :]\n",
    "    Y_val[i] = pairs[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
